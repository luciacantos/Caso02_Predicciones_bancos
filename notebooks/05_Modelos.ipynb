{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81362b6",
   "metadata": {},
   "source": [
    "# üìù Celda 1 ‚Äî Imports, rutas y semillas\n",
    "\n",
    "\n",
    "Configuramos TensorFlow/Keras, rutas a secuencias del Cuaderno 4 y la semilla para reproducibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import itertools, json, time, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Reproducibilidad\n",
    "SEED = 42\n",
    "np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# Rutas de los datasets secuenciales (creados en Cuaderno 4)\n",
    "SEQ_ROOT = Path(\"../data/processed/seq\")\n",
    "\n",
    "# Directorios de salida\n",
    "FIG_DIR = Path(\"../reports/figures\")\n",
    "OUT_DIR = Path(\"../reports/models\")\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"TF:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b05c4d",
   "metadata": {},
   "source": [
    "# üìù Celda 2 ‚Äî Carga de secuencias (train/val/test)\n",
    "\n",
    "Utilidades para cargar X/y y metadatos de cada ticker y window_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9becac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_seq(ticker: str, W: int):\n",
    "    base = SEQ_ROOT / ticker / f\"w{W}\"\n",
    "    Xtr = np.load(base / \"X_train.npy\"); ytr = np.load(base / \"y_train.npy\")\n",
    "    Xva = np.load(base / \"X_val.npy\");   yva = np.load(base / \"y_val.npy\")\n",
    "    Xte = np.load(base / \"X_test.npy\");  yte = np.load(base / \"y_test.npy\")\n",
    "    with open(base / \"meta.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        meta = json.load(f)\n",
    "    return (Xtr,ytr), (Xva,yva), (Xte,yte), meta\n",
    "\n",
    "# Prueba r√°pida\n",
    "for tkr in [\"BBVA\",\"SAN\"]:\n",
    "    for W in [10,20,30]:\n",
    "        (Xtr,ytr),(Xva,yva),(Xte,yte),meta = load_seq(tkr, W)\n",
    "        print(f\"{tkr} W={W} -> Xtr{Xtr.shape}, Xva{Xva.shape}, Xte{Xte.shape}, feats={meta['n_features']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd2a073",
   "metadata": {},
   "source": [
    "# üìù Celda 3 ‚Äî Constructor de modelos (SimpleRNN / LSTM / GRU)\n",
    "\n",
    "Funci√≥n para construir el modelo con una sola capa recurrente y cabeza densa lineal (como en el TFG). Optimizaci√≥n con Adam y p√©rdida MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0b59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_type: str, units: int, n_features: int, window_size: int, lr: float) -> keras.Model:\n",
    "    model = keras.Sequential(name=f\"{model_type}_u{units}_w{window_size}_lr{lr}\")\n",
    "    if model_type == \"SimpleRNN\":\n",
    "        model.add(layers.SimpleRNN(units, input_shape=(window_size, n_features)))\n",
    "    elif model_type == \"LSTM\":\n",
    "        model.add(layers.LSTM(units, input_shape=(window_size, n_features)))\n",
    "    elif model_type == \"GRU\":\n",
    "        model.add(layers.GRU(units, input_shape=(window_size, n_features)))\n",
    "    else:\n",
    "        raise ValueError(\"model_type debe ser 'SimpleRNN', 'LSTM' o 'GRU'\")\n",
    "    model.add(layers.Dense(1))\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt, loss=\"mse\", metrics=[\"mse\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae93feb",
   "metadata": {},
   "source": [
    "# üìù Celda 4 ‚Äî Entrenamiento y evaluaci√≥n (con EarlyStopping)\n",
    "\n",
    "Entrenamos con EarlyStopping (paciencia 2, monitor val_loss) y devolvemos historia, m√©tricas de val/test y predicciones para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_eval(model_type: str, tkr: str, W: int, units: int, batch: int, lr: float, epochs: int):\n",
    "    (Xtr,ytr),(Xva,yva),(Xte,yte),meta = load_seq(tkr, W)\n",
    "    model = build_model(model_type, units, meta[\"n_features\"], W, lr)\n",
    "    es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        Xtr, ytr,\n",
    "        validation_data=(Xva,yva),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch,\n",
    "        verbose=0,\n",
    "        callbacks=[es]\n",
    "    )\n",
    "    # Evaluaci√≥n\n",
    "    val_mse = model.evaluate(Xva, yva, verbose=0)[0]\n",
    "    test_mse = model.evaluate(Xte, yte, verbose=0)[0]\n",
    "    yhat_test = model.predict(Xte, verbose=0).ravel()\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"history\": history.history,\n",
    "        \"val_mse\": float(val_mse),\n",
    "        \"test_mse\": float(test_mse),\n",
    "        \"y_true_test\": yte,\n",
    "        \"y_pred_test\": yhat_test\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c166798",
   "metadata": {},
   "source": [
    "# üìù Celda 5 ‚Äî Curvas de p√©rdida (5/7/10 √©pocas) como en el TFG\n",
    "\n",
    "Para cada modelo (SimpleRNN, LSTM, GRU) y cada ticker, dibujamos tres curvas de p√©rdida (train/val) con epochs = 5, 7, 10.\n",
    "Usamos una configuraci√≥n base units=64, batch=32, lr=1e-3 (mismo esp√≠ritu del TFG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37169e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CFG = dict(units=64, batch=32, lr=1e-3)\n",
    "EPOCHS_LIST = [5,7,10]\n",
    "MODELS = [\"SimpleRNN\",\"LSTM\",\"GRU\"]\n",
    "TICKERS = [\"BBVA\",\"SAN\"]\n",
    "WINDOW_FOR_PLOTS = 20  # el TFG suele fijar una ventana para las curvas; puedes cambiar a 10 o 30 si prefieres\n",
    "\n",
    "def plot_losses(histories, title):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    for ep, h in histories.items():\n",
    "        plt.plot(h[\"loss\"], label=f\"train (e={ep})\")\n",
    "        plt.plot(h[\"val_loss\"], label=f\"val (e={ep})\", linestyle=\"--\")\n",
    "    plt.title(title); plt.xlabel(\"√âpoca\"); plt.ylabel(\"MSE (p√©rdida)\")\n",
    "    plt.grid(alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "for tkr in TICKERS:\n",
    "    for m in MODELS:\n",
    "        hist_dict = {}\n",
    "        for ep in EPOCHS_LIST:\n",
    "            res = fit_and_eval(m, tkr, WINDOW_FOR_PLOTS, **BASE_CFG, epochs=ep)\n",
    "            hist_dict[ep] = res[\"history\"]\n",
    "        plot_losses(hist_dict, f\"{tkr} ¬∑ {m} ‚Äî Curvas de p√©rdida (W={WINDOW_FOR_PLOTS})\")\n",
    "\n",
    "        # (Opcional) guarda la √∫ltima figura si quieres reportarla\n",
    "        # plt.savefig(FIG_DIR / f\"{tkr}_{m}_loss_curves_W{WINDOW_FOR_PLOTS}.png\", dpi=130)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9670e",
   "metadata": {},
   "source": [
    "# üìù Celda 6 ‚Äî Grid Search (MSE en validaci√≥n) y ranking\n",
    "\n",
    "Aplicamos Grid Search (exhaustivo) con los rangos del TFG y guardamos un ranking por ticker y modelo.\n",
    "La m√©trica de selecci√≥n es val_mse. Al final, re-evaluamos la mejor combinaci√≥n tambi√©n en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcbb1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID = {\n",
    "    \"window\": [10,20,30],\n",
    "    \"units\": [32,64,128],\n",
    "    \"batch\": [32,64],\n",
    "    \"lr\": [1e-3, 5e-4],\n",
    "}\n",
    "MAX_EPOCHS = 10  # en el TFG se prueban 5/7/10; para el grid usamos 10 con EarlyStopping\n",
    "\n",
    "def grid_search_for_model(tkr: str, model_type: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for W, U, B, LR in itertools.product(GRID[\"window\"], GRID[\"units\"], GRID[\"batch\"], GRID[\"lr\"]):\n",
    "        res = fit_and_eval(model_type, tkr, W, units=U, batch=B, lr=LR, epochs=MAX_EPOCHS)\n",
    "        rows.append({\n",
    "            \"ticker\": tkr, \"model\": model_type,\n",
    "            \"window\": W, \"units\": U, \"batch\": B, \"lr\": LR,\n",
    "            \"val_mse\": res[\"val_mse\"], \"test_mse\": res[\"test_mse\"]\n",
    "        })\n",
    "        # Guardado incremental (por si se corta la ejecuci√≥n)\n",
    "        pd.DataFrame(rows).to_csv(OUT_DIR / f\"grid_partial_{tkr}_{model_type}.csv\", index=False)\n",
    "    df_rank = pd.DataFrame(rows).sort_values([\"val_mse\",\"test_mse\"]).reset_index(drop=True)\n",
    "    return df_rank\n",
    "\n",
    "all_ranks = []\n",
    "for tkr in TICKERS:\n",
    "    for m in MODELS:\n",
    "        print(f\"‚Ü≥ Grid Search: {tkr} ¬∑ {m}\")\n",
    "        rank_df = grid_search_for_model(tkr, m)\n",
    "        rank_df.to_csv(OUT_DIR / f\"grid_{tkr}_{m}.csv\", index=False)\n",
    "        all_ranks.append(rank_df.assign(order=range(1, len(rank_df)+1)))\n",
    "\n",
    "grid_all = pd.concat(all_ranks, ignore_index=True)\n",
    "grid_all.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39718c8d",
   "metadata": {},
   "source": [
    "# üìù Celda 7 ‚Äî Top-10 por modelo y ticker (tabla para el informe)\n",
    "\n",
    "Mostramos y guardamos la tabla Top-10 (como en el TFG) para cada combinaci√≥n ticker/model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e3f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = []\n",
    "for tkr in TICKERS:\n",
    "    for m in MODELS:\n",
    "        dfm = grid_all[(grid_all[\"ticker\"]==tkr) & (grid_all[\"model\"]==m)].sort_values([\"val_mse\",\"test_mse\"]).head(10)\n",
    "        dfm.to_csv(OUT_DIR / f\"top10_{tkr}_{m}.csv\", index=False)\n",
    "        print(f\"\\n=== {tkr} ¬∑ {m} ‚Äî Top-10 (por val_mse) ===\")\n",
    "        display(dfm)\n",
    "        tops.append(dfm.assign(kind=f\"{tkr}_{m}\"))\n",
    "\n",
    "top_all = pd.concat(tops, ignore_index=True)\n",
    "top_all.to_csv(OUT_DIR / \"top10_all.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf48562",
   "metadata": {},
   "source": [
    "# üìù Celda 8 ‚Äî Selecci√≥n del mejor por modelo (para las gr√°ficas ‚Äúreal vs predicho‚Äù)\n",
    "\n",
    "Elegimos la mejor configuraci√≥n (m√≠nimo val_mse) para cada ticker/model, reentrenamos (EarlyStopping) y graficamos real vs predicho en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_config(df: pd.DataFrame, tkr: str, m: str):\n",
    "    sub = df[(df[\"ticker\"]==tkr) & (df[\"model\"]==m)].sort_values([\"val_mse\",\"test_mse\"]).head(1).iloc[0]\n",
    "    return dict(W=int(sub[\"window\"]), U=int(sub[\"units\"]), B=int(sub[\"batch\"]), LR=float(sub[\"lr\"]))\n",
    "\n",
    "def plot_real_pred(y_true, y_pred, title):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(y_true, label=\"Real (Close t+1)\", linewidth=1.2)\n",
    "    plt.plot(y_pred, label=\"Predicho\", linewidth=1.2)\n",
    "    plt.title(title); plt.xlabel(\"√çndice temporal (test)\"); plt.ylabel(\"Close (escalado)\")\n",
    "    plt.grid(alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "best_runs = []\n",
    "for tkr in TICKERS:\n",
    "    for m in MODELS:\n",
    "        cfg = best_config(grid_all, tkr, m)\n",
    "        res = fit_and_eval(m, tkr, cfg[\"W\"], cfg[\"U\"], cfg[\"B\"], cfg[\"LR\"], epochs=MAX_EPOCHS)\n",
    "        plot_real_pred(res[\"y_true_test\"], res[\"y_pred_test\"], f\"{tkr} ¬∑ {m} ‚Äî Mejor configuraci√≥n (test)\")\n",
    "        best_runs.append({\n",
    "            \"ticker\": tkr, \"model\": m, \"window\": cfg[\"W\"], \"units\": cfg[\"U\"],\n",
    "            \"batch\": cfg[\"B\"], \"lr\": cfg[\"LR\"], \"val_mse\": res[\"val_mse\"], \"test_mse\": res[\"test_mse\"]\n",
    "        })\n",
    "\n",
    "best_table = pd.DataFrame(best_runs).sort_values([\"ticker\",\"test_mse\"])\n",
    "best_table.to_csv(OUT_DIR / \"best_models_summary.csv\", index=False)\n",
    "best_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b28f8cf",
   "metadata": {},
   "source": [
    "# üìù Celda 9 ‚Äî Comparativa final de MSE (barras)\n",
    "\n",
    "Gr√°fico de barras comparando el MSE de test de los mejores modelos (SimpleRNN vs LSTM vs GRU) para cada ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8093b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_compare(best_table, ticker):\n",
    "    sub = best_table[best_table[\"ticker\"]==ticker].sort_values(\"test_mse\")\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar(sub[\"model\"], sub[\"test_mse\"])\n",
    "    for i,(m,v) in enumerate(zip(sub[\"model\"], sub[\"test_mse\"])):\n",
    "        plt.text(i, v, f\"{v:.5f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    plt.title(f\"{ticker} ‚Äî MSE (test) mejores modelos\")\n",
    "    plt.ylabel(\"MSE (test)\"); plt.grid(axis=\"y\", alpha=0.2)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "for tkr in TICKERS:\n",
    "    bar_compare(best_table, tkr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cec641",
   "metadata": {},
   "source": [
    "# üìù Celda 10 ‚Äî Guardado opcional de modelos (H5)\n",
    "\n",
    "Si quieres conservar los pesos de los mejores para incluirlos en el repo/entrega:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6acbc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODELS = True\n",
    "\n",
    "if SAVE_MODELS:\n",
    "    for row in best_table.itertuples(index=False):\n",
    "        (Xtr,ytr),(Xva,yva),(Xte,yte),meta = load_seq(row.ticker, int(row.window))\n",
    "        model = build_model(row.model, int(row.units), meta[\"n_features\"], int(row.window), float(row.lr))\n",
    "        es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)\n",
    "        model.fit(Xtr, ytr, validation_data=(Xva,yva), epochs=MAX_EPOCHS, batch_size=int(row.batch), verbose=0, callbacks=[es])\n",
    "        path = OUT_DIR / f\"{row.ticker}_{row.model}_w{row.window}_u{row.units}_b{row.batch}_lr{row.lr}.h5\"\n",
    "        model.save(path)\n",
    "        print(\"üíæ Guardado:\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a876cfc",
   "metadata": {},
   "source": [
    "## üìù Resumen\n",
    "\n",
    "\n",
    "\n",
    "- Curvas de p√©rdida (5/7/10 √©pocas) para SimpleRNN, LSTM y GRU en BBVA y SAN (W=20).\n",
    "\n",
    "- Grid Search con hiperpar√°metros del TFG:\n",
    "\n",
    "window_size = 10, 20, 30\n",
    "\n",
    "units = 32, 64, 128\n",
    "\n",
    "batch_size = 32, 64\n",
    "\n",
    "learning_rate = 0.001, 0.0005\n",
    "\n",
    "- M√©trica de selecci√≥n: MSE (validaci√≥n).\n",
    "\n",
    "- Top-10 por ticker/model (CSV en reports/models).\n",
    "\n",
    "- Mejores configuraciones reentrenadas y evaluadas en test con gr√°ficas ‚Äúreal vs predicho‚Äù.\n",
    "\n",
    "- Barras comparativas de MSE (SimpleRNN vs LSTM vs GRU) por ticker.\n",
    "\n",
    "- Modelos guardados (.h5) para reproducibilidad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
