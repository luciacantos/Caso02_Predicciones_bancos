{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af4b5f7",
   "metadata": {},
   "source": [
    "# Celda 1 ‚Äî Imports, semillas, hilos, rutas y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Imports base ====\n",
    "import os, time, gc, itertools, json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==== Reproducibilidad ====\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# ==== Control de hilos (Windows/CPU) para estabilidad ====\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")\n",
    "tf.config.threading.set_intra_op_parallelism_threads(4)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(4)\n",
    "\n",
    "# ==== Rutas ====\n",
    "DATA_DIR   = Path(\"../data/processed/seq\")\n",
    "REPORT_DIR = Path(\"../reports/models\")\n",
    "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# util para tiempo bonito\n",
    "def mmss(t):\n",
    "    m = int(t // 60); s = int(t % 60)\n",
    "    return f\"{m:02d}:{s:02d}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a2e38",
   "metadata": {},
   "source": [
    "# Celda 2 ‚Äî Carga de secuencias (de Cuaderno 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647119a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_seq(ticker: str, window: int):\n",
    "    base = DATA_DIR / ticker / f\"w{window}\"\n",
    "    Xtr = np.load(base/\"X_train.npy\"); ytr = np.load(base/\"y_train.npy\"); idx_tr = pd.DatetimeIndex(np.load(base/\"idx_train.npy\"))\n",
    "    Xva = np.load(base/\"X_val.npy\");   yva = np.load(base/\"y_val.npy\");   idx_va = pd.DatetimeIndex(np.load(base/\"idx_val.npy\"))\n",
    "    Xte = np.load(base/\"X_test.npy\");  yte = np.load(base/\"y_test.npy\");  idx_te = pd.DatetimeIndex(np.load(base/\"idx_test.npy\"))\n",
    "    meta = json.load(open(base/\"meta.json\",\"r\"))\n",
    "    return (Xtr,ytr),(Xva,yva),(Xte,yte),meta\n",
    "\n",
    "# Prueba r√°pida (opcional; puedes comentar si ya lo sabes)\n",
    "for tkr in [\"BBVA\",\"SAN\"]:\n",
    "    for W in [10,20,30]:\n",
    "        (Xtr,ytr),(Xva,yva),(Xte,yte),meta = load_seq(tkr, W)\n",
    "        print(f\"{tkr} W={W} -> Xtr{Xtr.shape}, Xva{Xva.shape}, Xte{Xte.shape}, feats={meta['n_features']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4a0b8",
   "metadata": {},
   "source": [
    "# Celda 3 ‚Äî Baseline de persistencia (diagn√≥stico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_persistence(X3: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Devuelve el √∫ltimo Close de la ventana (asumimos Close como 1¬™ feature).\"\"\"\n",
    "    return X3[:, -1, 0]\n",
    "\n",
    "for tkr in [\"BBVA\",\"SAN\"]:\n",
    "    (Xtr,ytr),(Xva,yva),(Xte,yte),meta = load_seq(tkr, 20)\n",
    "    yhat_naive = naive_persistence(Xte)\n",
    "    mse_naive = np.mean((yhat_naive - yte)**2)\n",
    "    print(f\"{tkr} ¬∑ Naive (persistencia) ¬∑ MSE test = {mse_naive:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13342c40",
   "metadata": {},
   "source": [
    "# Celda 4 ‚Äî Constructor de modelos (robusto y sin warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_type: str, units: int, n_features: int, window_size: int, lr: float) -> keras.Model:\n",
    "    inp = keras.Input(shape=(window_size, n_features), name=\"seq\")\n",
    "    if model_type == \"SimpleRNN\":\n",
    "        x = layers.SimpleRNN(units, return_sequences=True, dropout=0.1, recurrent_dropout=0.1,\n",
    "                             kernel_regularizer=regularizers.l2(1e-5))(inp)\n",
    "        x = layers.SimpleRNN(units, dropout=0.1, recurrent_dropout=0.1)(x)\n",
    "    elif model_type == \"LSTM\":\n",
    "        x = layers.LSTM(units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(inp)\n",
    "        x = layers.LSTM(units, dropout=0.2, recurrent_dropout=0.2)(x)\n",
    "    elif model_type == \"GRU\":\n",
    "        x = layers.GRU(units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(inp)\n",
    "        x = layers.GRU(units, dropout=0.2, recurrent_dropout=0.2)(x)\n",
    "    else:\n",
    "        raise ValueError(\"model_type debe ser 'SimpleRNN', 'LSTM' o 'GRU'\")\n",
    "    out = layers.Dense(1, name=\"y\")(x)\n",
    "\n",
    "    model = keras.Model(inp, out, name=f\"{model_type}_u{units}_w{window_size}\")\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=\"mse\", metrics=[\"mse\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066a9785",
   "metadata": {},
   "source": [
    "# Celda 5 ‚Äî Callbacks de progreso y l√≠mite por combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd5430",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 80     # puedes ajustar\n",
    "PATIENCE   = 3       # EarlyStopping\n",
    "MAX_SECS   = 30*60   # ‚è±Ô∏è l√≠mite por combo (None para sin l√≠mite)\n",
    "\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.t0 = time.time()\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"    ¬∑ epoch {epoch+1}/{self.params.get('epochs', '?')} ...\", flush=True)\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(f\"    ¬∑ done in {mmss(time.time()-self.t0)}\", flush=True)\n",
    "\n",
    "class StopAfterSeconds(keras.callbacks.Callback):\n",
    "    def __init__(self, seconds=None):\n",
    "        super().__init__(); self.seconds = seconds\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.t0 = time.time()\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.seconds is not None and (time.time()-self.t0) > self.seconds:\n",
    "            print(\"    ‚è±Ô∏è  Paro por tiempo m√°ximo de combo\", flush=True)\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a288d7c",
   "metadata": {},
   "source": [
    "# Celda 6 ‚Äî Entrenar con logs + evaluar (sustituye a fit_and_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_eval_with_logs(model_type, tkr, W, units, batch, lr, epochs=MAX_EPOCHS):\n",
    "    # Datos\n",
    "    (Xtr,ytr),(Xva,yva),(Xte,yte),meta = load_seq(tkr, W)\n",
    "    n_features = meta[\"n_features\"]\n",
    "\n",
    "    # Modelo\n",
    "    model = build_model(model_type, units, n_features, W, lr)\n",
    "\n",
    "    # Datasets tf.data (m√°s estables en memoria)\n",
    "    ds_tr = tf.data.Dataset.from_tensor_slices((Xtr, ytr)).batch(batch).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    ds_va = tf.data.Dataset.from_tensor_slices((Xva, yva)).batch(batch)\n",
    "    ds_te = tf.data.Dataset.from_tensor_slices((Xte, yte)).batch(batch)\n",
    "\n",
    "    # Callbacks\n",
    "    cbs = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True),\n",
    "           TimeHistory(),\n",
    "           StopAfterSeconds(MAX_SECS)]\n",
    "\n",
    "    # Entrenamiento\n",
    "    h = model.fit(ds_tr, validation_data=ds_va, epochs=epochs, verbose=0, callbacks=cbs)\n",
    "\n",
    "    # Evaluaci√≥n\n",
    "    y_pred_va = model.predict(ds_va, verbose=0).ravel()\n",
    "    y_pred_te = model.predict(ds_te, verbose=0).ravel()\n",
    "    val_mse = float(np.mean((y_pred_va - yva)**2))\n",
    "    test_mse = float(np.mean((y_pred_te - yte)**2))\n",
    "\n",
    "    # Limpieza memoria\n",
    "    keras.backend.clear_session(); del model\n",
    "    gc.collect()\n",
    "\n",
    "    return {\"val_mse\": val_mse, \"test_mse\": test_mse}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55a975",
   "metadata": {},
   "source": [
    "# Celda 7 ‚Äî Configuraci√≥n del grid (con recorte SAN¬∑LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0106a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = [\"BBVA\", \"SAN\"]\n",
    "MODELS  = [\"SimpleRNN\", \"LSTM\", \"GRU\"]\n",
    "\n",
    "GRID = {\n",
    "    \"window\": [10,20,30],\n",
    "    \"units\":  [32,64,128],\n",
    "    \"batch\":  [32,64],\n",
    "    \"lr\":     [1e-3, 5e-4],\n",
    "}\n",
    "\n",
    "def grid_for(ticker, model):\n",
    "    g = {k: v[:] for k, v in GRID.items()}\n",
    "    # ‚ö†Ô∏è Cuello t√≠pico: SAN ¬∑ LSTM ‚Äî lo recortamos para no atascar\n",
    "    if ticker == \"SAN\" and model == \"LSTM\":\n",
    "        g[\"window\"] = [20,30]\n",
    "        g[\"units\"]  = [64,128]\n",
    "        g[\"batch\"]  = [32]   # quita 64 para evitar swap\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc98106",
   "metadata": {},
   "source": [
    "# Celda 8 ‚Äî (Opcional) Curvas de p√©rdida r√°pidas (5/7/10 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baefeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CFG = dict(units=64, batch=32, lr=1e-3)\n",
    "EPOCHS_LIST = [5,7,10]\n",
    "WINDOW_FOR_PLOTS = 20\n",
    "\n",
    "def train_history(model_type, tkr, W, units, batch, lr, epochs):\n",
    "    (Xtr,ytr),(Xva,yva),(Xte,yte),meta = load_seq(tkr, W)\n",
    "    model = build_model(model_type, units, meta[\"n_features\"], W, lr)\n",
    "    es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)\n",
    "    h = model.fit(Xtr, ytr, validation_data=(Xva,yva), epochs=epochs, batch_size=batch, verbose=0, callbacks=[es])\n",
    "    hist = {\"loss\": h.history[\"loss\"], \"val_loss\": h.history.get(\"val_loss\", [])}\n",
    "    keras.backend.clear_session(); del model; gc.collect()\n",
    "    return hist\n",
    "\n",
    "def plot_losses(histories, title):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    for ep, h in histories.items():\n",
    "        plt.plot(h[\"loss\"], label=f\"train (e={ep})\")\n",
    "        if len(h[\"val_loss\"]):\n",
    "            plt.plot(h[\"val_loss\"], label=f\"val (e={ep})\", linestyle=\"--\")\n",
    "    plt.title(title); plt.xlabel(\"√âpoca\"); plt.ylabel(\"MSE (p√©rdida)\")\n",
    "    plt.grid(alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "for tkr in TICKERS:\n",
    "    for m in MODELS:\n",
    "        hist_dict = {}\n",
    "        for ep in EPOCHS_LIST:\n",
    "            hist_dict[ep] = train_history(m, tkr, WINDOW_FOR_PLOTS, **BASE_CFG, epochs=ep)\n",
    "        plot_losses(hist_dict, f\"{tkr} ¬∑ {m} ‚Äî Curvas de p√©rdida (W={WINDOW_FOR_PLOTS})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107a1d6",
   "metadata": {},
   "source": [
    "# Celda 9 ‚Äî Grid Search con progreso, guardado incremental y reanudaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f531ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = REPORT_DIR\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def grid_search_for_model(tkr: str, model_type: str) -> pd.DataFrame:\n",
    "    partial_csv = OUT_DIR / f\"grid_partial_{tkr}_{model_type}.csv\"\n",
    "    rows = []\n",
    "\n",
    "    # Reanudaci√≥n si existe parcial\n",
    "    if partial_csv.exists():\n",
    "        prev = pd.read_csv(partial_csv)\n",
    "        rows = prev.to_dict(\"records\")\n",
    "        print(f\"‚è≠Ô∏è  Reanudando: {len(rows)} combos ya terminados\")\n",
    "\n",
    "    done = {(r[\"window\"], r[\"units\"], r[\"batch\"], float(r[\"lr\"])) for r in rows}\n",
    "    g = grid_for(tkr, model_type)\n",
    "    combos = list(itertools.product(g[\"window\"], g[\"units\"], g[\"batch\"], g[\"lr\"]))\n",
    "    total = len(combos)\n",
    "\n",
    "    for i, (W, U, B, LR) in enumerate(combos, start=1):\n",
    "        if (W,U,B,float(LR)) in done:\n",
    "            print(f\"‚è≠Ô∏è  {tkr} ¬∑ {model_type} ¬∑ combo {i}/{total} (W={W},U={U},B={B},lr={LR}) ya estaba\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n‚ñ∂ {tkr} ¬∑ {model_type} ¬∑ combo {i}/{total}  (W={W}, U={U}, B={B}, lr={LR})\")\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            res = fit_and_eval_with_logs(model_type, tkr, W, units=U, batch=B, lr=LR, epochs=MAX_EPOCHS)\n",
    "            status = \"ok\"\n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ö†Ô∏è  Error: {type(e).__name__}: {e}\")\n",
    "            res = {\"val_mse\": np.nan, \"test_mse\": np.nan}\n",
    "            status = f\"error:{type(e).__name__}\"\n",
    "\n",
    "        dt = time.time() - t0\n",
    "        print(f\"    ‚Ü≥ val_mse={res['val_mse']:.6f} ¬∑ test_mse={res['test_mse']:.6f} ¬∑ {mmss(dt)}\")\n",
    "\n",
    "        rows.append({\n",
    "            \"ticker\": tkr, \"model\": model_type,\n",
    "            \"window\": W, \"units\": U, \"batch\": B, \"lr\": LR,\n",
    "            \"val_mse\": res[\"val_mse\"], \"test_mse\": res[\"test_mse\"],\n",
    "            \"secs\": round(dt,1), \"status\": status\n",
    "        })\n",
    "        pd.DataFrame(rows).to_csv(partial_csv, index=False)\n",
    "\n",
    "        time.sleep(0.2)  # respiro\n",
    "        gc.collect()\n",
    "\n",
    "    df_rank = pd.DataFrame(rows).sort_values([\"val_mse\",\"test_mse\"], na_position=\"last\").reset_index(drop=True)\n",
    "    return df_rank\n",
    "\n",
    "all_ranks = []\n",
    "for tkr in TICKERS:\n",
    "    for m in MODELS:\n",
    "        print(f\"\\n==== Grid Search: {tkr} ¬∑ {m} ====\")\n",
    "        rank_df = grid_search_for_model(tkr, m)\n",
    "        rank_df.to_csv(OUT_DIR / f\"grid_{tkr}_{m}.csv\", index=False)\n",
    "        all_ranks.append(rank_df.assign(order=range(1, len(rank_df)+1)))\n",
    "\n",
    "grid_all = pd.concat(all_ranks, ignore_index=True)\n",
    "grid_all.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a36cb",
   "metadata": {},
   "source": [
    "# Celda 10 ‚Äî Top-10 por ticker/modelo y resumen ‚Äúmejor de cada uno‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-10 por grupo\n",
    "tops = []\n",
    "for tkr in TICKERS:\n",
    "    for m in MODELS:\n",
    "        dfm = grid_all[(grid_all[\"ticker\"]==tkr) & (grid_all[\"model\"]==m)].sort_values([\"val_mse\",\"test_mse\"]).head(10)\n",
    "        dfm.to_csv(OUT_DIR / f\"top10_{tkr}_{m}.csv\", index=False)\n",
    "        print(f\"\\n=== {tkr} ¬∑ {m} ‚Äî Top-10 (por val_mse) ===\")\n",
    "        display(dfm)\n",
    "        tops.append(dfm.assign(kind=f\"{tkr}_{m}\"))\n",
    "\n",
    "top_all = pd.concat(tops, ignore_index=True)\n",
    "top_all.to_csv(OUT_DIR / \"top10_all.csv\", index=False)\n",
    "\n",
    "# Mejor de cada grupo\n",
    "best_rows = []\n",
    "for t in TICKERS:\n",
    "    for m in MODELS:\n",
    "        best_rows.append(grid_all[(grid_all.ticker==t)&(grid_all.model==m)].sort_values([\"val_mse\",\"test_mse\"]).iloc[0])\n",
    "best_table = pd.DataFrame(best_rows).reset_index(drop=True)\n",
    "best_table.to_csv(OUT_DIR / \"best_models_summary.csv\", index=False)\n",
    "display(best_table)\n",
    "print(\"‚úÖ Guardado resumen:\", OUT_DIR / \"best_models_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7403f61b",
   "metadata": {},
   "source": [
    "# Celda 11 ‚Äî Real vs Predicho de los mejores (plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd6f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_config(df: pd.DataFrame, tkr: str, m: str):\n",
    "    sub = df[(df[\"ticker\"]==tkr) & (df[\"model\"]==m)].sort_values([\"val_mse\",\"test_mse\"]).head(1).iloc[0]\n",
    "    return dict(W=int(sub[\"window\"]), U=int(sub[\"units\"]), B=int(sub[\"batch\"]), LR=float(sub[\"lr\"]))\n",
    "\n",
    "def plot_real_pred(y_true, y_pred, title):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(y_true, label=\"Real (Close t+1)\", linewidth=1.2)\n",
    "    plt.plot(y_pred, label=\"Predicho\", linewidth=1.2)\n",
    "    plt.title(title); plt.xlabel(\"√çndice temporal (test)\"); plt.ylabel(\"Close (escalado)\")\n",
    "    plt.grid(alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "best_runs = []\n",
    "for tkr in TICKERS:\n",
    "    for m in MODELS:\n",
    "        cfg = best_config(grid_all, tkr, m)\n",
    "        # Entrenamos SOLO para graficar (pocas √©pocas por rapidez)\n",
    "        (Xtr,ytr),(Xva,yva),(Xte,yte),meta = load_seq(tkr, cfg[\"W\"])\n",
    "        model = build_model(m, cfg[\"U\"], meta[\"n_features\"], cfg[\"W\"], cfg[\"LR\"])\n",
    "        es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "        model.fit(Xtr, ytr, validation_data=(Xva,yva), epochs=min(20, MAX_EPOCHS), batch_size=cfg[\"B\"], verbose=0, callbacks=[es])\n",
    "        yhat = model.predict(Xte, verbose=0).ravel()\n",
    "        val_mse = float(np.mean((model.predict(Xva, verbose=0).ravel() - yva)**2))\n",
    "        test_mse = float(np.mean((yhat - yte)**2))\n",
    "        plot_real_pred(yte, yhat, f\"{tkr} ¬∑ {m} ‚Äî Mejor configuraci√≥n (test)\")\n",
    "        best_runs.append({\n",
    "            \"ticker\": tkr, \"model\": m, \"window\": cfg[\"W\"], \"units\": cfg[\"U\"],\n",
    "            \"batch\": cfg[\"B\"], \"lr\": cfg[\"LR\"], \"val_mse\": val_mse, \"test_mse\": test_mse\n",
    "        })\n",
    "        keras.backend.clear_session(); del model; gc.collect()\n",
    "\n",
    "best_table = pd.DataFrame(best_runs).sort_values([\"ticker\",\"test_mse\"])\n",
    "best_table.to_csv(OUT_DIR / \"best_models_summary.csv\", index=False)\n",
    "display(best_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2400eace",
   "metadata": {},
   "source": [
    "# Celda 12 ‚Äî Mejora vs persistencia para los mejores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34805afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(a,b): return float(np.mean((a-b)**2))\n",
    "\n",
    "for row in best_table.itertuples(index=False):\n",
    "    (Xtr,ytr),(Xva,yva),(Xte,yte),meta = load_seq(row.ticker, int(row.window))\n",
    "    model = build_model(row.model, int(row.units), meta[\"n_features\"], int(row.window), float(row.lr))\n",
    "    es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "    model.fit(Xtr, ytr, validation_data=(Xva,yva), epochs=min(30, MAX_EPOCHS), batch_size=int(row.batch), verbose=0, callbacks=[es])\n",
    "    yhat = model.predict(Xte, verbose=0).ravel()\n",
    "    ynaive = naive_persistence(Xte)\n",
    "    mse_model = mse(yte, yhat)\n",
    "    mse_naive = mse(yte, ynaive)\n",
    "    imp = 100*(1 - mse_model/mse_naive)\n",
    "    print(f\"{row.ticker} ¬∑ {row.model} (W={row.window}, U={row.units}) ‚Üí MSE={mse_model:.6f} | Naive={mse_naive:.6f} | Mejora={imp:.2f}%\")\n",
    "    keras.backend.clear_session(); del model; gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163a8b8d",
   "metadata": {},
   "source": [
    "# Celda 13 ‚Äî Comparativa MSE (barras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf0c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_compare(best_table, ticker):\n",
    "    sub = best_table[best_table[\"ticker\"]==ticker].sort_values(\"test_mse\")\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar(sub[\"model\"], sub[\"test_mse\"])\n",
    "    for i,(m,v) in enumerate(zip(sub[\"model\"], sub[\"test_mse\"])):\n",
    "        plt.text(i, v, f\"{v:.5f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    plt.title(f\"{ticker} ‚Äî MSE (test) mejores modelos\")\n",
    "    plt.ylabel(\"MSE (test)\"); plt.grid(axis=\"y\", alpha=0.2)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "for tkr in TICKERS:\n",
    "    bar_compare(best_table, tkr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cabee5",
   "metadata": {},
   "source": [
    "# Celda 14 ‚Äî Guardar modelos .h5 (para Cuaderno 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a44c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODELS = True\n",
    "\n",
    "if SAVE_MODELS:\n",
    "    for row in best_table.itertuples(index=False):\n",
    "        (Xtr,ytr),(Xva,yva),(Xte,yte),meta = load_seq(row.ticker, int(row.window))\n",
    "        model = build_model(row.model, int(row.units), meta[\"n_features\"], int(row.window), float(row.lr))\n",
    "        es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "        model.fit(Xtr, ytr, validation_data=(Xva,yva), epochs=min(30, MAX_EPOCHS), batch_size=int(row.batch), verbose=0, callbacks=[es])\n",
    "        path = OUT_DIR / f\"{row.ticker}_{row.model}_w{row.window}_u{row.units}_b{row.batch}_lr{row.lr}.h5\"\n",
    "        model.save(path)\n",
    "        print(\"üíæ Guardado:\", path)\n",
    "        keras.backend.clear_session(); del model; gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
