{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e117bc",
   "metadata": {},
   "source": [
    "# üìù Celda 1 ‚Äî Par√°metros y utilidades\n",
    "\n",
    "Explicaci√≥n: fijamos el rango de evaluaci√≥n (noviembre), la fecha de corte (entrenamos hasta 31-oct) y funciones para indicadores (mismas que Cuaderno 2, resumidas aqu√≠)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5e32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODO DE TRABAJO ===\n",
    "# True  -> Opci√≥n A: Cargar modelos .h5 guardados en el Cuaderno 5 (no entrena)\n",
    "# False -> Opci√≥n B: No hay .h5; re-entrena una sola vez (final fit) con datos <= 31-oct\n",
    "LOAD_SAVED_MODELS = True\n",
    "\n",
    "TICKERS = {\"BBVA\": \"BBVA.MC\", \"SAN\": \"SAN.MC\"}\n",
    "\n",
    "# Fechas de evaluaci√≥n (aj√∫stalas si quieres un rango m√°s corto)\n",
    "CUTOFF     = \"2025-10-31\"   # entrenar / ajustar hasta aqu√≠ (inclusive)\n",
    "EVAL_START = \"2025-11-01\"   # evaluar a partir de aqu√≠\n",
    "EVAL_END   = \"2025-11-10\"   # por ejemplo, los \"primeros d√≠as de noviembre\"\n",
    "\n",
    "# Rutas a artefactos del cuaderno 5\n",
    "from pathlib import Path\n",
    "MODELS_DIR = Path(\"../reports/models\")\n",
    "BEST_CSV   = MODELS_DIR / \"best_models_summary.csv\"  # generado en el 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc7549",
   "metadata": {},
   "source": [
    "# üìù Celda 2 ‚Äî Descargar datos, crear indicadores y dataset de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "def add_indicators(df: pd.DataFrame, prefix: str):\n",
    "    c, h, l = df[\"Close\"], df[\"High\"], df[\"Low\"]\n",
    "    out = df.copy()\n",
    "    out[f\"SMA5_{prefix}\"]  = c.rolling(5).mean()\n",
    "    out[f\"SMA10_{prefix}\"] = c.rolling(10).mean()\n",
    "    out[f\"SMA20_{prefix}\"] = c.rolling(20).mean()\n",
    "    out[f\"EMA10_{prefix}\"] = c.ewm(span=10, adjust=False).mean()\n",
    "    out[f\"STD10_{prefix}\"] = c.rolling(10).std()\n",
    "    delta = c.diff()\n",
    "    up, down = delta.clip(lower=0), (-delta).clip(lower=0)\n",
    "    roll_up = up.ewm(alpha=1/14, adjust=False).mean()\n",
    "    roll_dn = down.ewm(alpha=1/14, adjust=False).mean()\n",
    "    rs = roll_up / roll_dn.replace(0, np.nan)\n",
    "    out[f\"RSI14_{prefix}\"] = 100 - 100/(1+rs)\n",
    "    tr = pd.concat([(h-l), (h-c.shift()).abs(), (l-c.shift()).abs()], axis=1).max(axis=1)\n",
    "    out[f\"ATR14_{prefix}\"] = tr.rolling(14).mean()\n",
    "    return out\n",
    "\n",
    "def tidy(df: pd.DataFrame, prefix: str):\n",
    "    cols = {\n",
    "        \"Close\": f\"Close_{prefix}\", \"Volume\": f\"Volume_{prefix}\",\n",
    "        \"Open\": f\"Open_{prefix}\",   \"High\":   f\"High_{prefix}\",\n",
    "        \"Low\":  f\"Low_{prefix}\",    \"Adj Close\": f\"AdjClose_{prefix}\"\n",
    "    }\n",
    "    return (df.rename(columns=cols)\n",
    "            [[f\"Close_{prefix}\", f\"Volume_{prefix}\", f\"Open_{prefix}\",\n",
    "              f\"High_{prefix}\", f\"Low_{prefix}\", f\"AdjClose_{prefix}\",\n",
    "              f\"SMA5_{prefix}\", f\"SMA10_{prefix}\", f\"SMA20_{prefix}\",\n",
    "              f\"EMA10_{prefix}\", f\"STD10_{prefix}\", f\"RSI14_{prefix}\", f\"ATR14_{prefix}\"]])\n",
    "\n",
    "raw = {}\n",
    "for k, yft in TICKERS.items():\n",
    "    d = yf.download(yft, start=\"2000-01-01\", end=EVAL_END, auto_adjust=False, actions=True, progress=False)\n",
    "    d = add_indicators(d, k).dropna()\n",
    "    raw[k] = tidy(d, k)\n",
    "\n",
    "data = raw[\"BBVA\"].join(raw[\"SAN\"], how=\"inner\").dropna()\n",
    "print(\"Rango:\", data.index.min().date(), \"‚Üí\", data.index.max().date(), \"| shape:\", data.shape)\n",
    "data.tail(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f808ca66",
   "metadata": {},
   "source": [
    "# üìù Celda 3 ‚Äî Split por fecha y escalado sin fuga (fit en train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8babcfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_mask = data.index <= pd.to_datetime(CUTOFF)\n",
    "eval_mask  = (data.index >= pd.to_datetime(EVAL_START)) & (data.index <= pd.to_datetime(EVAL_END))\n",
    "\n",
    "data_train = data.loc[train_mask].copy()\n",
    "data_eval  = data.loc[eval_mask].copy()\n",
    "\n",
    "def fit_apply_scalers_per_ticker(df_train, df_all, ticker):\n",
    "    cols = [c for c in df_all.columns if c.endswith(f\"_{ticker}\")]\n",
    "    sc = MinMaxScaler().fit(df_train[cols])  # SOLO train\n",
    "    scaled = df_all.copy()\n",
    "    scaled[cols] = sc.transform(df_all[cols])\n",
    "    return scaled, sc, cols\n",
    "\n",
    "scaled, sc_bbva, bbva_cols = fit_apply_scalers_per_ticker(data_train, data, \"BBVA\")\n",
    "scaled, sc_san,  san_cols  = fit_apply_scalers_per_ticker(data_train, scaled, \"SAN\")\n",
    "\n",
    "scaled_train = scaled.loc[train_mask].copy()\n",
    "scaled_eval  = scaled.loc[eval_mask].copy()\n",
    "\n",
    "print(\"Train:\", scaled_train.shape, \"| Eval:\", scaled_eval.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6781d2",
   "metadata": {},
   "source": [
    "# üìù Celda 4 ‚Äî Utilidades para ventanas y baseline de persistencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_window_from_end(df_scaled_all: pd.DataFrame, end_date: pd.Timestamp, cols_order: list, W: int):\n",
    "    # usa W d√≠as consecutivos hasta end_date (incluido)\n",
    "    if end_date not in df_scaled_all.index:\n",
    "        # tomar el √∫ltimo d√≠a h√°bil anterior\n",
    "        prev = df_scaled_all.index[df_scaled_all.index < end_date]\n",
    "        if len(prev)==0: return None\n",
    "        end_date = prev.max()\n",
    "    end_pos = df_scaled_all.index.get_indexer_for([end_date])[0]\n",
    "    start_pos = end_pos - (W-1)\n",
    "    if start_pos < 0: return None\n",
    "    idx = df_scaled_all.index[start_pos:end_pos+1]\n",
    "    X = df_scaled_all.loc[idx, cols_order].values.astype(np.float32)\n",
    "    return X, idx\n",
    "\n",
    "def naive_persistence_from_window(X_window: np.ndarray):\n",
    "    # asume Close como 1¬™ columna de las features del ticker (nuestro orden lo cumple)\n",
    "    return float(X_window[-1, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781605db",
   "metadata": {},
   "source": [
    "# üìù Celda 5 ‚Äî Cargar modelos (Opci√≥n A) o Final Fit (Opci√≥n B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e58402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import pandas as pd\n",
    "\n",
    "def build_model(model_type: str, units: int, n_features: int, window_size: int, lr: float):\n",
    "    inp = keras.Input(shape=(window_size, n_features))\n",
    "    if model_type == \"SimpleRNN\":\n",
    "        x = layers.SimpleRNN(units, return_sequences=True, dropout=0.1, recurrent_dropout=0.1,\n",
    "                             kernel_regularizer=regularizers.l2(1e-5))(inp)\n",
    "        x = layers.SimpleRNN(units, dropout=0.1, recurrent_dropout=0.1)(x)\n",
    "    elif model_type == \"LSTM\":\n",
    "        x = layers.LSTM(units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(inp)\n",
    "        x = layers.LSTM(units, dropout=0.2, recurrent_dropout=0.2)(x)\n",
    "    elif model_type == \"GRU\":\n",
    "        x = layers.GRU(units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(inp)\n",
    "        x = layers.GRU(units, dropout=0.2, recurrent_dropout=0.2)(x)\n",
    "    out = layers.Dense(1)(x)\n",
    "    model = keras.Model(inp, out)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "best = pd.read_csv(BEST_CSV)\n",
    "MODELOS = {}  # dict: (ticker, model) -> {\"model\": keras.Model, \"W\": int, \"cols\": list[str]}\n",
    "\n",
    "if LOAD_SAVED_MODELS:\n",
    "    # === Opci√≥n A: cargar .h5 guardados en el 5 ===\n",
    "    def h5_name(row):\n",
    "        return f\"{row.ticker}_{row.model}_w{int(row.window)}_u{int(row.units)}_b{int(row.batch)}_lr{float(row.lr)}.h5\"\n",
    "\n",
    "    for r in best.itertuples(index=False):\n",
    "        path = MODELS_DIR / h5_name(r)\n",
    "        model = keras.models.load_model(path)\n",
    "        cols = [c for c in scaled.columns if c.endswith(f\"_{r.ticker}\")]\n",
    "        MODELOS[(r.ticker, r.model)] = {\"model\": model, \"W\": int(r.window), \"cols\": cols}\n",
    "        print(\"‚úî Cargado\", path.name)\n",
    "\n",
    "else:\n",
    "    # === Opci√≥n B: final fit con hiperpar√°metros ganadores (sin tocar noviembre) ===\n",
    "    for r in best.itertuples(index=False):\n",
    "        tkr, m, W = r.ticker, r.model, int(r.window)\n",
    "        cols = [c for c in scaled.columns if c.endswith(f\"_{tkr}\")]\n",
    "        # construir dataset (t+1) en escalado con todo <= cutoff\n",
    "        Xfull = scaled_train[cols].copy()\n",
    "        yfull = scaled_train[f\"Close_{tkr}\"].shift(-1)  # objetivo t+1\n",
    "        data_xy = Xfull.join(yfull.rename(\"y\")).dropna()\n",
    "        # ventaneo\n",
    "        Xv = data_xy[cols].values.astype(np.float32)\n",
    "        yv = data_xy[\"y\"].values.astype(np.float32)\n",
    "        xs, ys = [], []\n",
    "        for i in range(W-1, len(Xv)):\n",
    "            xs.append(Xv[i-W+1:i+1, :])\n",
    "            ys.append(yv[i])\n",
    "        X3 = np.array(xs); y1 = np.array(ys)\n",
    "        # split interno: 90%/10% para EarlyStopping\n",
    "        cut = int(len(X3)*0.9)\n",
    "        Xtr, ytr, Xva, yva = X3[:cut], y1[:cut], X3[cut:], y1[cut:]\n",
    "        model = build_model(m, int(r.units), X3.shape[2], W, float(r.lr))\n",
    "        es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "        model.fit(Xtr, ytr, validation_data=(Xva,yva), epochs=30, batch_size=int(r.batch), verbose=0, callbacks=[es])\n",
    "        MODELOS[(tkr, m)] = {\"model\": model, \"W\": W, \"cols\": cols}\n",
    "        print(f\"‚úÖ Entrenado {tkr} ¬∑ {m} (W={W}) con datos <= {CUTOFF}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc21d64",
   "metadata": {},
   "source": [
    "# üìù Celda 6 ‚Äî Predicci√≥n walk-forward en noviembre y baseline persistencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab939287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "rows = []\n",
    "for (tkr, m), info in MODELOS.items():\n",
    "    W, cols, model = info[\"W\"], info[\"cols\"], info[\"model\"]\n",
    "    # iterar por cada d√≠a de evaluaci√≥n\n",
    "    for d in scaled_eval.index:\n",
    "        # la ventana termina en el d√≠a h√°bil anterior a d\n",
    "        # construimos ventana hasta d-1:\n",
    "        prev_idx = scaled.index[scaled.index < d]\n",
    "        if len(prev_idx) == 0: \n",
    "            continue\n",
    "        end_date = prev_idx.max()\n",
    "        win = make_window_from_end(scaled, end_date, cols, W)\n",
    "        if win is None: \n",
    "            continue\n",
    "        Xw, idxw = win\n",
    "        y_pred = float(model.predict(Xw.reshape(1, W, len(cols)), verbose=0).ravel()[0])\n",
    "        y_true = float(scaled.loc[d, f\"Close_{tkr}\"])\n",
    "        y_naiv = naive_persistence_from_window(Xw)\n",
    "        rows.append({\"date\": d, \"ticker\": tkr, \"model\": m, \"y_true\": y_true, \"y_pred\": y_pred, \"y_naive\": y_naiv})\n",
    "\n",
    "res = pd.DataFrame(rows).sort_values([\"ticker\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "def summarize(df):\n",
    "    out = []\n",
    "    for (t,m), g in df.groupby([\"ticker\",\"model\"]):\n",
    "        mse = mean_squared_error(g.y_true, g.y_pred)\n",
    "        mae = mean_absolute_error(g.y_true, g.y_pred)\n",
    "        mse_n = mean_squared_error(g.y_true, g.y_naive)\n",
    "        imp = 100*(1 - mse/mse_n)\n",
    "        out.append({\"ticker\":t,\"model\":m,\"MSE_nov\":mse,\"MAE_nov\":mae,\"MSE_naive\":mse_n,\"Mejora_vs_naive_%\":imp,\"n_dias\":len(g)})\n",
    "    return pd.DataFrame(out).sort_values([\"ticker\",\"MSE_nov\"])\n",
    "\n",
    "summary = summarize(res)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ff801",
   "metadata": {},
   "source": [
    "# üìù Celda 7 ‚Äî Gr√°ficas ‚ÄúReal vs Predicho vs Naive‚Äù (Noviembre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_nov(df, ticker):\n",
    "    best_m = (summary[summary[\"ticker\"]==ticker].sort_values(\"MSE_nov\").iloc[0][\"model\"])\n",
    "    g = df[(df[\"ticker\"]==ticker) & (df[\"model\"]==best_m)]\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(g[\"date\"], g[\"y_true\"], label=\"Real (Close)\", linewidth=1.5)\n",
    "    plt.plot(g[\"date\"], g[\"y_pred\"], label=f\"Predicho ({best_m})\", linewidth=1.5)\n",
    "    plt.plot(g[\"date\"], g[\"y_naive\"], label=\"Naive\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.title(f\"{ticker} ¬∑ Noviembre ‚Äî Real vs Predicho (mejor: {best_m})\")\n",
    "    plt.grid(alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_nov(res, \"BBVA\")\n",
    "plot_nov(res, \"SAN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b94527",
   "metadata": {},
   "source": [
    "# üìù Celda 8 ‚Äî Guardado de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f0ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = Path(\"../reports/noviembre\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "res.to_csv(OUT / \"detalle_noviembre.csv\", index=False)\n",
    "summary.to_csv(OUT / \"resumen_noviembre.csv\", index=False)\n",
    "print(\"‚úÖ Guardado en\", OUT)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f6d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Exportar predicciones para la app Streamlit ===\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Reemplaza estas variables por tus DataFrames finales:\n",
    "# df_bbva_pred y df_san_pred deben tener: date, y_true (puede ser NaN), y_pred\n",
    "# Si tus nombres son otros, adapta abajo.\n",
    "\n",
    "def _standardize(df: pd.DataFrame, tk: str) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    # normaliza nombres\n",
    "    rename = {c.lower().strip(): c for c in out.columns}\n",
    "    out.columns = [c.lower().strip() for c in out.columns]\n",
    "    # columnas m√≠nimas\n",
    "    needed = {\"date\", \"y_pred\"}\n",
    "    assert needed.issubset(set(out.columns)), f\"Faltan columnas {needed - set(out.columns)}\"\n",
    "    if \"y_true\" not in out.columns:\n",
    "        out[\"y_true\"] = pd.NA\n",
    "    out[\"ticker\"] = tk\n",
    "    out[\"date\"] = pd.to_datetime(out[\"date\"]).dt.date\n",
    "    out = out[[\"date\", \"ticker\", \"y_true\", \"y_pred\"]].drop_duplicates()\n",
    "    return out\n",
    "\n",
    "df_bbva_std = _standardize(df_bbva_pred, \"BBVA\")\n",
    "df_san_std  = _standardize(df_san_pred,  \"SAN\")\n",
    "df_app = pd.concat([df_bbva_std, df_san_std], ignore_index=True).sort_values([\"ticker\",\"date\"])\n",
    "\n",
    "# Rango de inter√©s: principios de noviembre (ajusta si quieres)\n",
    "df_app = df_app[(df_app[\"date\"] >= pd.to_datetime(\"2025-11-01\").date()) &\n",
    "                (df_app[\"date\"] <= pd.to_datetime(\"2025-11-10\").date())]\n",
    "\n",
    "out_path = Path(\"data/app\")\n",
    "out_path.mkdir(parents=True, exist_ok=True)\n",
    "df_app.to_csv(out_path / \"predicciones.csv\", index=False, encoding=\"utf-8\")\n",
    "print(f\"[OK] Exportado: {out_path / 'predicciones.csv'}  | Filas={len(df_app)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eeae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_extended_forecast(df_scaled_all, res_df, ticker, days_hist=15):\n",
    "    \"\"\"\n",
    "    Muestra los √∫ltimos d√≠as reales antes del 31-oct y contin√∫a con las predicciones de noviembre.\n",
    "    \"\"\"\n",
    "    cutoff = pd.to_datetime(CUTOFF)\n",
    "    eval_start = pd.to_datetime(EVAL_START)\n",
    "    eval_end = pd.to_datetime(EVAL_END)\n",
    "\n",
    "    # === tramo real antes del corte (√∫ltimos N d√≠as previos) ===\n",
    "    hist_mask = (df_scaled_all.index >= cutoff - pd.Timedelta(days=days_hist)) & \\\n",
    "                (df_scaled_all.index <= cutoff)\n",
    "    hist = df_scaled_all.loc[hist_mask, f\"Close_{ticker}\"].reset_index()\n",
    "    hist.rename(columns={\"Date\": \"date\", f\"Close_{ticker}\": \"y_hist\"}, inplace=True)\n",
    "\n",
    "    # === tramo predicho (noviembre) ===\n",
    "    best_m = (summary[summary[\"ticker\"] == ticker]\n",
    "              .sort_values(\"MSE_nov\")\n",
    "              .iloc[0][\"model\"])\n",
    "    preds = res_df[(res_df[\"ticker\"] == ticker) & (res_df[\"model\"] == best_m)][\n",
    "        [\"date\", \"y_pred\", \"y_true\"]\n",
    "    ].copy()\n",
    "    preds[\"period\"] = \"Predicci√≥n (noviembre)\"\n",
    "\n",
    "    # === unir ===\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(hist[\"date\"], hist[\"y_hist\"], color=\"black\", linewidth=2.0, label=\"Hist√≥rico (octubre)\")\n",
    "    plt.plot(preds[\"date\"], preds[\"y_true\"], color=\"green\", linestyle=\"-\", label=\"Real noviembre\")\n",
    "    plt.plot(preds[\"date\"], preds[\"y_pred\"], color=\"orange\", linestyle=\"--\", label=f\"Predicho ({best_m})\")\n",
    "\n",
    "    plt.axvline(cutoff, color=\"gray\", linestyle=\":\", linewidth=1.5)\n",
    "    plt.text(cutoff, plt.ylim()[0], \"Corte 31-oct\", fontsize=9, color=\"gray\", ha=\"right\", va=\"bottom\")\n",
    "\n",
    "    plt.title(f\"{ticker} ‚Äî Hist√≥rico y Predicci√≥n noviembre ({best_m})\", fontsize=13)\n",
    "    plt.xlabel(\"Fecha\"); plt.ylabel(\"Precio de cierre (escalado)\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_extended_forecast(scaled, res, \"BBVA\", days_hist=15)\n",
    "plot_extended_forecast(scaled, res, \"SAN\", days_hist=15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
